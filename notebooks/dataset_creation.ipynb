{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5088b1a0-1f84-4a41-a220-4460280fa3e8",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44249010-2d1c-4493-8952-9a845d0b7d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a01f06-9c9e-4fcf-8542-b1eda86f21c5",
   "metadata": {},
   "source": [
    "First, we create the regular expressions to find the annotations of interest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58586107-b271-4702-90e8-3837f4b06e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains the ethicity attributes that appear 5 times or more in the flickr8k corpus\n",
    "nonwhite_re = re.compile(r'(\\ban?)? ?(african|asian|black|japanese|indian|oriental|middle[ -]eastern|dark[ -]skinned|african[ -]american) (girls?|boys?|m[ae]n|wom[ae]n|persons?|individuals?|people|guys?|dudes?|lad(y|ies)|kids?|child(ren)?|chicks?)\\s')\n",
    "# group 0: \"an asian girl \"\n",
    "# group 1: \"an\"\n",
    "# group 2: \"asian\"\n",
    "# group 3: \"girl\"\n",
    "white_re = re.compile(r'(\\ban?)? ?\\b((white|fair|pale)([\\s-]skinned)?|caucasian) (girls?|boys?|m[ae]n|wom[ae]n|persons?|individuals?|people|guys?|dudes?|lad(y|ies)|kids?|child(ren)?|chicks?)\\s')\n",
    "# group 0: \"a white boy \"\n",
    "# group 1: \"a\"\n",
    "# group 2: \"white\"\n",
    "# group 5: \"boy\" (because some extra groups to account for \"fair-skinned\" etc)\n",
    "people_re = re.compile(r'(\\ban?)?\\s?\\b(girls?|boys?|m[ae]n|wom[ae]n|persons?|individuals?|people|guys?|dudes?|lad(y|ies)|kids?|child(ren)?|chicks?)\\s')\n",
    "# group 0: \" child \" (line.split(group0))\n",
    "# group 1: \"\" (a/an)\n",
    "# group 2: \"child\" (just add \"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd5f63-5360-4c8a-8c55-fb3481e1b3d9",
   "metadata": {},
   "source": [
    "Then we load the data (Flickr8k and COCO):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6b234b-691a-476c-a510-51c94f73e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/srv/data/gussodato/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99bccb13-917f-4407-832e-d047becb51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir, 'flickr8k/Flickr8k.token.txt')) as f:\n",
    "    lines = [line.lower().strip().split('\\t') for line in f]\n",
    "\n",
    "flickr_df = pd.DataFrame(lines)\n",
    "img_id_col = [row[:-2] for row in flickr_df[0]]\n",
    "flickr_df[2] = img_id_col\n",
    "flickr_df[3] = 'flickr8k/Flicker8k_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee6721e2-c03f-4ac3-a2f2-8a214c3df521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#0</td>\n",
       "      <td>a child in a pink dress is climbing up a set o...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#1</td>\n",
       "      <td>a girl going into a wooden building .</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#2</td>\n",
       "      <td>a little girl climbing into a wooden playhouse .</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#3</td>\n",
       "      <td>a little girl climbing the stairs to her playh...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg#4</td>\n",
       "      <td>a little girl in a pink dress going into a woo...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40455</th>\n",
       "      <td>997722733_0cb5439472.jpg#0</td>\n",
       "      <td>a man in a pink shirt climbs a rock face</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40456</th>\n",
       "      <td>997722733_0cb5439472.jpg#1</td>\n",
       "      <td>a man is rock climbing high in the air .</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40457</th>\n",
       "      <td>997722733_0cb5439472.jpg#2</td>\n",
       "      <td>a person in a red shirt climbing up a rock fac...</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40458</th>\n",
       "      <td>997722733_0cb5439472.jpg#3</td>\n",
       "      <td>a rock climber in a red shirt .</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40459</th>\n",
       "      <td>997722733_0cb5439472.jpg#4</td>\n",
       "      <td>a rock climber practices on a rock climbing wa...</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>flickr8k/Flicker8k_Dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40460 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  \\\n",
       "0      1000268201_693b08cb0e.jpg#0   \n",
       "1      1000268201_693b08cb0e.jpg#1   \n",
       "2      1000268201_693b08cb0e.jpg#2   \n",
       "3      1000268201_693b08cb0e.jpg#3   \n",
       "4      1000268201_693b08cb0e.jpg#4   \n",
       "...                            ...   \n",
       "40455   997722733_0cb5439472.jpg#0   \n",
       "40456   997722733_0cb5439472.jpg#1   \n",
       "40457   997722733_0cb5439472.jpg#2   \n",
       "40458   997722733_0cb5439472.jpg#3   \n",
       "40459   997722733_0cb5439472.jpg#4   \n",
       "\n",
       "                                                       1  \\\n",
       "0      a child in a pink dress is climbing up a set o...   \n",
       "1                  a girl going into a wooden building .   \n",
       "2       a little girl climbing into a wooden playhouse .   \n",
       "3      a little girl climbing the stairs to her playh...   \n",
       "4      a little girl in a pink dress going into a woo...   \n",
       "...                                                  ...   \n",
       "40455           a man in a pink shirt climbs a rock face   \n",
       "40456           a man is rock climbing high in the air .   \n",
       "40457  a person in a red shirt climbing up a rock fac...   \n",
       "40458                    a rock climber in a red shirt .   \n",
       "40459  a rock climber practices on a rock climbing wa...   \n",
       "\n",
       "                               2                           3  \n",
       "0      1000268201_693b08cb0e.jpg  flickr8k/Flicker8k_Dataset  \n",
       "1      1000268201_693b08cb0e.jpg  flickr8k/Flicker8k_Dataset  \n",
       "2      1000268201_693b08cb0e.jpg  flickr8k/Flicker8k_Dataset  \n",
       "3      1000268201_693b08cb0e.jpg  flickr8k/Flicker8k_Dataset  \n",
       "4      1000268201_693b08cb0e.jpg  flickr8k/Flicker8k_Dataset  \n",
       "...                          ...                         ...  \n",
       "40455   997722733_0cb5439472.jpg  flickr8k/Flicker8k_Dataset  \n",
       "40456   997722733_0cb5439472.jpg  flickr8k/Flicker8k_Dataset  \n",
       "40457   997722733_0cb5439472.jpg  flickr8k/Flicker8k_Dataset  \n",
       "40458   997722733_0cb5439472.jpg  flickr8k/Flicker8k_Dataset  \n",
       "40459   997722733_0cb5439472.jpg  flickr8k/Flicker8k_Dataset  \n",
       "\n",
       "[40460 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flickr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fa1144c-b65e-4300-8158-0e64bcf602a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir, 'coco/annotations/captions_train2017.json')) as f:\n",
    "    coco_train = json.load(f)\n",
    "    \n",
    "coco_df = pd.DataFrame(coco_train['annotations'])\n",
    "coco_df['img'] = ['0'*(12-len(str(id)))+str(id)+'.jpg' for id in coco_df['image_id']]\n",
    "coco_df.drop(labels='image_id', axis=1, inplace=True)\n",
    "coco_df.columns = range(len(coco_df.columns))\n",
    "coco_df[1] = coco_df[1].str.lower()\n",
    "coco_df[3] = 'coco/train2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6629b91d-96a2-4351-8956-857b3cc0271f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>a bicycle replica with a clock as the front wh...</td>\n",
       "      <td>000000203564.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>a room with blue walls and a white sink and door.</td>\n",
       "      <td>000000322141.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>a car that seems to be parked illegally behind...</td>\n",
       "      <td>000000016977.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>a large passenger airplane flying through the ...</td>\n",
       "      <td>000000106140.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>there is a gol plane taking off in a partly cl...</td>\n",
       "      <td>000000106140.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591748</th>\n",
       "      <td>829655</td>\n",
       "      <td>a slice of bread is covered with a sour cream ...</td>\n",
       "      <td>000000133071.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591749</th>\n",
       "      <td>829658</td>\n",
       "      <td>a long plate hold some fries with some sliders...</td>\n",
       "      <td>000000410182.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591750</th>\n",
       "      <td>829665</td>\n",
       "      <td>two women sit and pose with stuffed animals.</td>\n",
       "      <td>000000180285.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591751</th>\n",
       "      <td>829693</td>\n",
       "      <td>white plate with a lot of guacamole and an ext...</td>\n",
       "      <td>000000133071.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591752</th>\n",
       "      <td>829717</td>\n",
       "      <td>a dinner plate has a lemon wedge garnishment.</td>\n",
       "      <td>000000133071.jpg</td>\n",
       "      <td>coco/train2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>591753 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                                  1  \\\n",
       "0           37  a bicycle replica with a clock as the front wh...   \n",
       "1           49  a room with blue walls and a white sink and door.   \n",
       "2           89  a car that seems to be parked illegally behind...   \n",
       "3           98  a large passenger airplane flying through the ...   \n",
       "4          101  there is a gol plane taking off in a partly cl...   \n",
       "...        ...                                                ...   \n",
       "591748  829655  a slice of bread is covered with a sour cream ...   \n",
       "591749  829658  a long plate hold some fries with some sliders...   \n",
       "591750  829665       two women sit and pose with stuffed animals.   \n",
       "591751  829693  white plate with a lot of guacamole and an ext...   \n",
       "591752  829717      a dinner plate has a lemon wedge garnishment.   \n",
       "\n",
       "                       2               3  \n",
       "0       000000203564.jpg  coco/train2017  \n",
       "1       000000322141.jpg  coco/train2017  \n",
       "2       000000016977.jpg  coco/train2017  \n",
       "3       000000106140.jpg  coco/train2017  \n",
       "4       000000106140.jpg  coco/train2017  \n",
       "...                  ...             ...  \n",
       "591748  000000133071.jpg  coco/train2017  \n",
       "591749  000000410182.jpg  coco/train2017  \n",
       "591750  000000180285.jpg  coco/train2017  \n",
       "591751  000000133071.jpg  coco/train2017  \n",
       "591752  000000133071.jpg  coco/train2017  \n",
       "\n",
       "[591753 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd866d-ba84-407c-a52a-7e4daf1b6632",
   "metadata": {},
   "source": [
    "Now we collect the annotations that match our regular expressions and keep one for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62f7c9e1-3edc-4368-af72-af600a2c5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_annotations(df, people_re, normgroup_re, testgroup_re):\n",
    "    people_df = df[df[1].str.contains(people_re)]\n",
    "    testgroup_df = people_df[people_df[1].str.contains(testgroup_re)].drop_duplicates(2)\n",
    "    normgroup_df = people_df[people_df[1].str.contains(normgroup_re)].drop_duplicates(2)\n",
    "    both_df = testgroup_df[testgroup_df[2].isin(normgroup_df[2])]\n",
    "    testgroup_df = testgroup_df.drop(both_df.index)\n",
    "    normgroup_df = normgroup_df.drop(both_df.index)\n",
    "    seen_imgs = set([img for df in [testgroup_df, normgroup_df, both_df] for img in df[2]])\n",
    "    no_attribute_df = people_df.drop(people_df[people_df[2].isin(seen_imgs)].index)\n",
    "    return {'testgroup': testgroup_df, 'normgroup': normgroup_df, 'no_mention': no_attribute_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3099,
   "id": "837f98e2-0b81-49ab-8e12-65e850c15637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_812940/234031471.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  people_df = df[df[1].str.contains(people_re)]\n",
      "/tmp/ipykernel_812940/234031471.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  testgroup_df = people_df[people_df[1].str.contains(testgroup_re)].drop_duplicates(2)\n",
      "/tmp/ipykernel_812940/234031471.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  normgroup_df = people_df[people_df[1].str.contains(normgroup_re)].drop_duplicates(2)\n"
     ]
    }
   ],
   "source": [
    "flickr_set = filter_annotations(flickr_df, people_re, white_re, nonwhite_re)\n",
    "coco_set = filter_annotations(coco_df, people_re, white_re, nonwhite_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3086,
   "id": "c5009ea1-a0d3-48ba-9a69-847dbe2d145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_group_sizes(dataset, name):\n",
    "    print(name+':')\n",
    "    for groupname in dataset:\n",
    "        print(f'{groupname}: {len(dataset[groupname])} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3100,
   "id": "e6169381-c531-4740-a939-b7b460e4c6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flickr:\n",
      "testgroup: 238 examples\n",
      "normgroup: 14 examples\n",
      "no_mention: 24234 examples\n",
      "\n",
      "coco:\n",
      "testgroup: 442 examples\n",
      "normgroup: 53 examples\n",
      "no_mention: 209965 examples\n"
     ]
    }
   ],
   "source": [
    "print_group_sizes(flickr_set, 'flickr')\n",
    "print()\n",
    "print_group_sizes(coco_set, 'coco')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2866ff3-6ce1-4508-8e98-bd631df973d2",
   "metadata": {},
   "source": [
    "As can be seen from these numbers, the amount of annotations that mention ethnicity or skin color is much larger for images of non-white people than for images of white people. In order to get more balanced numbers, we need to manually collect a set of images of white people from the set of images where the annotators do not mention ethnicity. To do that, I create an iterator that shows the images and yields the image id, so that I can append it to a list if the person in the image seems to be white. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49520fe8-dfd4-4279-8995-f8a14d06b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_img(data_dict, datadir, sample_size=400):\n",
    "    samples_df = data_dict['no_mention'].drop_duplicates(2).sample(n=sample_size, axis=0)\n",
    "    img_ids = [(row[3], row[2]) for index, row in samples_df.iterrows()]\n",
    "    for img_id in img_ids:\n",
    "        display(Image(os.path.join(datadir, img_id[0], img_id[1])))\n",
    "        yield img_id[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2139,
   "id": "075d3622-839d-4c02-9b60-342110cfd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_flickr = Generate_img(flickr_set, datadir, 600)\n",
    "flickr_white = []\n",
    "flickr_nonwhite = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3064,
   "id": "a91f4f7a-8c73-46f7-8743-dabc38b45131",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3064], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imgid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerate_flickr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "imgid = next(generate_flickr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3063,
   "id": "8b0a0d99-50c4-4e9f-b744-4d33b54145d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_white.append(imgid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3008,
   "id": "478a7502-b68d-4af7-80fa-96bdfabb256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_nonwhite.append(imgid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2804,
   "id": "5cfdf8c6-ffb0-4e73-99d2-8e6a89b4bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case I make a mistake and need to remove the last item from the list:\n",
    "flickr_white = flickr_white[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2841,
   "id": "5001af01-1be2-4d00-85a7-4fa36d62d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_nonwhite = flickr_nonwhite[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3065,
   "id": "64842a89-369d-4ef3-9358-c35994de4baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 47)"
      ]
     },
     "execution_count": 3065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how many images were actually of white and non-white people respectively:\n",
    "len(flickr_white), len(flickr_nonwhite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3066,
   "id": "a4ed0956-0058-48ed-9b11-67042b40fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('flickr_white_imgs.txt', 'w') as f:\n",
    "    for img in flickr_white:\n",
    "        f.write(img+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "68b853ea-2f84-4f46-8a7e-6a022dc2b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_coco = Generate_img(coco_set, datadir, 800)\n",
    "coco_white = []\n",
    "coco_nonwhite = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2136,
   "id": "29bcec3c-a2ab-4a21-95b6-384a7ca24e1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imgid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerate_coco\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "imgid = next(generate_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2135,
   "id": "582537e0-8007-4f28-9762-db0e22ce8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_white.append(imgid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2088,
   "id": "4ff89fbd-0583-4e5d-8dda-7d504cf9ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_nonwhite.append(imgid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2046,
   "id": "791eb6a5-e734-480d-b6da-ef33b0c2522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, in case of mistakes:\n",
    "coco_white = coco_white[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "id": "d4afe687-746a-4e1c-9799-7d9c48e6b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_nonwhite = coco_nonwhite[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2137,
   "id": "f789c872-89f4-48d6-95ad-5aef1321522e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 85)"
      ]
     },
     "execution_count": 2137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_white), len(coco_nonwhite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2138,
   "id": "d238bdd3-adfc-4e3f-86a1-6cf8acb9b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coco_white_imgs.txt', 'w') as f:\n",
    "    for img in coco_white:\n",
    "        f.write(img+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b4731-da02-4eb3-945c-0e9af46dfa7d",
   "metadata": {},
   "source": [
    "Creating the contrasting sentence pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3068,
   "id": "a57a0518-c885-464b-87ba-5776aff72678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 297)"
      ]
     },
     "execution_count": 3068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('flickr_white_imgs.txt', 'r') as f:\n",
    "    flickr_white_imgs = [line.strip() for line in f]\n",
    "with open('coco_white_imgs.txt', 'r') as f:\n",
    "    coco_white_imgs = [line.strip() for line in f]\n",
    "len(flickr_white_imgs), len(coco_white_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3128,
   "id": "217563d2-351d-48f9-a20d-1f50a54c9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence_pairs(datadict, norm_imgs):\n",
    "    no_mention = datadict['no_mention']\n",
    "    norm_no_mention_df = no_mention[no_mention[2].isin(norm_imgs)].drop_duplicates(2)\n",
    "    norm_no_mention_df[4] = 'norm_no_mention'\n",
    "    datadict['normgroup'][4] = 'norm_mention'\n",
    "    test_mention_df = datadict['testgroup']\n",
    "    \n",
    "    # adding attribute to descriptions of white people:\n",
    "    newdescs_norm = []\n",
    "    for desc in norm_no_mention_df[1]:\n",
    "        match = re.search(people_re, desc)\n",
    "        if match[1] and match[1][-1]=='n':\n",
    "            splits = desc.split(match[1])\n",
    "            splits.insert(1, 'a white')\n",
    "            newdesc = ''.join(splits)\n",
    "            newdescs_norm.append(newdesc)\n",
    "        else:\n",
    "            splits = desc.split(match[2])\n",
    "            splits.insert(1, 'white '+match[2])\n",
    "            newdesc = ''.join(splits)\n",
    "            newdescs_norm.append(newdesc)\n",
    "            \n",
    "    norm_mention_df = pd.DataFrame(norm_no_mention_df[:])        \n",
    "    norm_mention_df[1] = newdescs_norm\n",
    "    norm_mention_df[4] = \"norm_mention\"\n",
    "    norm_mention_df = pd.concat([norm_mention_df[:], datadict['normgroup'][:]])\n",
    "\n",
    "    # removing attributes from descriptions of white people:\n",
    "    newdescs_nomention = []\n",
    "    for desc in datadict['normgroup'][1]:\n",
    "        match = re.search(white_re, desc)\n",
    "        if match[1]:\n",
    "            if match[1][-1]=='n' and match[3][0] != 'i':\n",
    "                splits = desc.split(match[0])\n",
    "                splits.insert(1, 'a '+match[3]+' ')\n",
    "                newdesc = ''.join(splits)\n",
    "                newdescs_nomention.append(newdesc)\n",
    "            elif match[1]=='a' and match[3][0] == 'i':\n",
    "                splits = desc.split(match[0])\n",
    "                splits.insert(1, 'an '+match[3]+' ')\n",
    "                newdesc = ''.join(splits)\n",
    "                newdescs_nomention.append(newdesc)\n",
    "            else:\n",
    "                splits = desc.split(match[2]+' ')\n",
    "                newdesc = ''.join(splits)\n",
    "                newdescs_nomention.append(newdesc)\n",
    "        else:\n",
    "            splits = desc.split(match[2]+' ')\n",
    "            newdesc = ''.join(splits)\n",
    "            newdescs_nomention.append(newdesc)\n",
    "    \n",
    "    new_norm_no_mention_df = datadict['normgroup'][:]\n",
    "    new_norm_no_mention_df[1] = newdescs_nomention\n",
    "    new_norm_no_mention_df[4] = \"norm_no_mention\"\n",
    "    norm_no_mention_df = pd.concat([norm_no_mention_df[:], new_norm_no_mention_df[:]])\n",
    "\n",
    "    # removing attributes from descriptions of nonwhite people:\n",
    "    newdescs_nomention = []\n",
    "    for desc in test_mention_df[1]:\n",
    "        match = re.search(nonwhite_re, desc)\n",
    "        if match[1]:\n",
    "            if match[1][-1]=='n' and match[3][0] != 'i':\n",
    "                splits = desc.split(match[0])\n",
    "                splits.insert(1, 'a '+match[3]+' ')\n",
    "                newdesc = ''.join(splits)\n",
    "                newdescs_nomention.append(newdesc)\n",
    "            elif match[1]=='a' and match[3][0] == 'i':\n",
    "                splits = desc.split(match[0])\n",
    "                splits.insert(1, 'an '+match[3]+' ')\n",
    "                newdesc = ''.join(splits)\n",
    "                newdescs_nomention.append(newdesc)\n",
    "            else:\n",
    "                splits = desc.split(match[2]+' ')\n",
    "                newdesc = ''.join(splits)\n",
    "                newdescs_nomention.append(newdesc)\n",
    "        else:\n",
    "            splits = desc.split(match[2]+' ')\n",
    "            newdesc = ''.join(splits)\n",
    "            newdescs_nomention.append(newdesc)\n",
    "    \n",
    "    test_no_mention_df = test_mention_df[:]\n",
    "    test_no_mention_df[1] = newdescs_nomention\n",
    "    test_no_mention_df[4] = \"test_no_mention\"\n",
    "    test_mention_df[4] = 'test_mention'\n",
    "    \n",
    "    return {'norm_no_mention': norm_no_mention_df, \n",
    "            'norm_mention': norm_mention_df, \n",
    "            'test_no_mention': test_no_mention_df, \n",
    "            'test_mention': test_mention_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3102,
   "id": "80da208f-0653-4f6a-82b7-c02283e5abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_full_set = make_sentence_pairs(flickr_set, flickr_white_imgs)\n",
    "coco_full_set = make_sentence_pairs(coco_set, coco_white_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6363026-fa7c-4037-9340-6ac197701eaf",
   "metadata": {},
   "source": [
    "Finally, let's combine the examples from Flickr8k and COCO, and save each separate test group as a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3120,
   "id": "25eff457-2196-41fd-8bb0-07d9f3af5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(datadicts):\n",
    "    '''Given a list of dicts output by the make_sentence_pairs() function, \n",
    "    returns a single dict where the dataframes corresponding to the same key of \n",
    "    the input dicts have been concatenated.\n",
    "    '''\n",
    "    keys = ['norm_no_mention', 'norm_mention', 'test_no_mention', 'test_mention']\n",
    "    newdict = {}\n",
    "    for key in keys:\n",
    "        newdict[key] = pd.concat([dict[key][:] for dict in datadicts])\n",
    "    return newdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3121,
   "id": "23710892-5b70-4edd-bee3-38b6ed40f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = combine_dataframes([flickr_full_set, coco_full_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3127,
   "id": "969179bf-05e9-4b3d-9201-b4caeaa8e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "for group in full_set:\n",
    "    full_set[group].to_csv(f'datasets/{group}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
